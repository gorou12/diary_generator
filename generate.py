import argparse
import json
import os
import re
from collections import Counter, defaultdict

import requests
from dotenv import load_dotenv
from jinja2 import Environment, FileSystemLoader

import generate_search_json

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# Jinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿
env = Environment(loader=FileSystemLoader("templates"))

# Notion API è¨­å®š
NOTION_API_KEY = os.getenv("NOTION_API_KEY")
DATABASE_ID = os.getenv("DATABASE_ID")
HEADERS = {
    "Authorization": f"Bearer {NOTION_API_KEY}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28",
}

CACHE_FILE = "data.json"  # Notionãƒ‡ãƒ¼ã‚¿ã®ä»®ç½®ãå ´æ‰€
ITEMS_PER_PAGE = 10  # 1ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã™ã‚‹æœ€å¤§æ•°


def paginate_list(items, items_per_page=20):
    """ãƒªã‚¹ãƒˆã‚’ãƒšãƒ¼ã‚¸ã”ã¨ã«åˆ†å‰²"""
    total_pages = (len(items) + items_per_page - 1) // items_per_page
    pages = [
        items[i * items_per_page : (i + 1) * items_per_page] for i in range(total_pages)
    ]
    return pages, total_pages


def fetch_notion_data(use_cache=False):
    """Notion API ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
    if use_cache and os.path.exists(CACHE_FILE):
        print("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™")
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)

    print("ğŸ”„ Notion API ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    response = requests.post(url, headers=HEADERS)

    if response.status_code == 200:
        print("âœ… Notion DBãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
        data = response.json()

        all_pages = []
        for item in data.get("results", []):
            properties = item.get("properties", {})
            date = properties.get("æ—¥ä»˜", {}).get("date", {}).get("start", "")
            page_id = item.get("id", "")
            is_public = properties.get("å…¬é–‹", {}).get("checkbox", False)

            if not date or not is_public:
                continue  # éå…¬é–‹ãƒšãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—

            topics = fetch_page_content(page_id)
            print(f"- æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿({date}) å–å¾—å®Œäº†")
            all_pages.append({"date": date, "topics": topics})

        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(all_pages, f, ensure_ascii=False, indent=4)
        print("âœ… Notionãƒ‡ãƒ¼ã‚¿å–å¾—ï¼†ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Œäº†")
        return all_pages
    else:
        print(f"âš ï¸ APIã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)
        return None


def fetch_page_content(page_id):
    """ç‰¹å®šã®ãƒšãƒ¼ã‚¸ã®è©³ç´°ã‚’å–å¾—ã—ã€æœ¬æ–‡ã‚’è§£æã—ã¦è¿”ã™"""
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    response = requests.get(url, headers=HEADERS)

    if response.status_code == 200:
        blocks = response.json().get("results", [])
        topics = []
        current_topic = {"title": "", "content": [], "hashtags": []}

        for block in blocks:
            block_type = block.get("type")
            text_elements = (
                block[block_type].get("rich_text", []) if block_type in block else []
            )
            text_content = "".join(
                t["text"]["content"] for t in text_elements if "text" in t
            ).strip()

            if block_type == "heading_3":  # Notionã®ã€Œè¦‹å‡ºã—3ã€ãŒãƒˆãƒ”ãƒƒã‚¯åã«ç›¸å½“
                if current_topic["title"] and "éå…¬é–‹" not in current_topic["hashtags"]:
                    topics.append(current_topic)  # æ—¢å­˜ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ä¿å­˜

                current_topic = {"title": text_content, "content": [], "hashtags": []}
            elif text_content.startswith("#"):
                hashtags = re.findall(r"#(\S+)", text_content)
                current_topic["hashtags"].extend(hashtags)
            elif text_content:
                current_topic["content"].append(text_content.replace("\n", "<br>"))

        if current_topic["title"] and "éå…¬é–‹" not in current_topic["hashtags"]:
            topics.append(current_topic)

        return topics
    else:
        print(f"âš ï¸ ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        return []


def load_notion_data():
    """ä¿å­˜ã•ã‚ŒãŸ Notion ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open("data.json", "r", encoding="utf-8") as f:
        return json.load(f)


def generate_top_page(data):
    """Jinja2ã§ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
    print("âœ… ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ç”Ÿæˆ")
    pages, total_pages = paginate_list(data, items_per_page=20)

    for idx, page_items in enumerate(pages):
        page_num = idx + 1
        filename = (
            f"output/index_{page_num}.html" if page_num > 1 else "output/index.html"
        )

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä½œæˆ
        pagination = ""
        if page_num > 1:
            prev_link = "index.html" if page_num == 2 else f"index_{page_num - 1}.html"
            pagination += f'<a href="{prev_link}">Â« å‰ã¸</a> '
        if page_num < total_pages:
            next_link = f"index_{page_num + 1}.html"
            pagination += f'<a href="{next_link}">æ¬¡ã¸ Â»</a>'

        # Jinja2 context
        context = {
            "title": "æ—¥è¨˜ãƒ–ãƒ­ã‚°",
            "entries": page_items,
            "pagination": pagination,
            "sidebar_content": "",  # å¿…è¦ãªã‚‰ã‚µã‚¤ãƒ‰ãƒãƒ¼äººæ°—ãƒˆãƒ”ãƒƒã‚¯ãªã©
        }

        render_template("index.html", context, filename)

    print("âœ… ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")


def generate_topic_pages(data):
    """ãƒˆãƒ”ãƒƒã‚¯/ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã”ã¨ã®å€‹åˆ¥ãƒšãƒ¼ã‚¸ã‚’Jinja2ã§ç”Ÿæˆ"""
    print("âœ… ãƒˆãƒ”ãƒƒã‚¯ãƒšãƒ¼ã‚¸ç”Ÿæˆ (Jinja2)")
    os.makedirs("output/topics", exist_ok=True)

    topic_dict = defaultdict(list)
    hashtag_dict = defaultdict(list)

    # ãƒˆãƒ”ãƒƒã‚¯ãƒ»ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®åé›†
    for page in data:
        date = page["date"]
        for topic in page["topics"]:
            topic_dict[topic["title"]].append((date, topic))
            for hashtag in topic["hashtags"]:
                hashtag_dict[hashtag].append((date, topic))

    # ãƒˆãƒ”ãƒƒã‚¯ï¼‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°çµ±åˆ
    combined_dict = {**topic_dict, **hashtag_dict}

    # å„ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«ç”Ÿæˆ
    for topic, entries in combined_dict.items():
        grouped_by_date = defaultdict(list)
        for date, entry in entries:
            grouped_by_date[date].append(entry)

        # Jinja2ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
        context = {
            "title": f"ãƒˆãƒ”ãƒƒã‚¯: {topic}",
            "topic_name": topic,
            "entries": [
                {
                    "date": f"{date[:4]}å¹´{date[5:7]}æœˆ{date[8:10]}æ—¥",
                    "date_raw": date,
                    "entries": [
                        {
                            "title": entry["title"],
                            "hashtags": entry["hashtags"],
                            "content": entry["content"],
                        }
                        for entry in grouped_by_date[date]
                    ],
                }
                for date in sorted(grouped_by_date.keys(), reverse=True)
            ],
            "sidebar_content": "",  # äººæ°—ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã©å…¥ã‚ŒãŸã„å ´åˆã¯ã“ã“ã«
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        output_file = f"output/topics/{topic}.html"
        render_template("topic.html", context, output_file)

    print("âœ… ãƒˆãƒ”ãƒƒã‚¯ãƒšãƒ¼ã‚¸ï¼ˆãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å«ã‚€ï¼‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼ï¼ˆJinja2ç‰ˆï¼‰")


def generate_date_pages(data):
    """æ—¥ä»˜ãƒšãƒ¼ã‚¸ã‚’Jinja2ã§ç”Ÿæˆ"""
    print("âœ… æ—¥ä»˜ãƒšãƒ¼ã‚¸ç”Ÿæˆ")
    os.makedirs("output/dates", exist_ok=True)

    for page in data:
        date = page["date"]
        topics = page["topics"]
        # date_formatted = f"{date[:4]}å¹´{date[5:7]}æœˆ{date[8:10]}æ—¥"  # YYYY-MM-DD â†’ YYYYå¹´MMæœˆDDæ—¥
        context = {
            "title": f"æ—¥è¨˜ - {date}",
            "date": date,
            "topics": topics,  # [{'title': ..., 'content': [...], 'hashtags': [...]}, ...]
            "sidebar_content": "",  # å¿…è¦ãªã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã©å…¥ã‚Œã‚‹
        }
        output_file = f"output/dates/{date}.html"
        render_template("date.html", context, output_file)
    print("âœ… æ—¥ä»˜ãƒšãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")


def generate_topics_index(data):
    """Jinja2ã§ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã®ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ã‚’ç”Ÿæˆ"""
    topic_counter = Counter()
    for page in data:
        for topic in page.get("topics", []):
            topic_counter[topic["title"]] += 1

    sorted_topics = topic_counter.most_common()
    popular_topics = [
        tpl for tpl in sorted_topics if tpl[1] >= 2
    ]  # CounterãŒ2ä»¥ä¸Šã®ã‚‚ã®ã ã‘

    pages, total_pages = paginate_list(sorted_topics, items_per_page=20)

    for idx, page_items in enumerate(pages):
        page_num = idx + 1
        filename = (
            f"output/topics_{page_num}.html" if page_num > 1 else "output/topics.html"
        )

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä½œæˆ
        pagination = ""
        if page_num > 1:
            prev_link = (
                "topics.html" if page_num == 2 else f"topics_{page_num - 1}.html"
            )
            pagination += f'<a href="{prev_link}">Â« å‰ã¸</a> '
        if page_num < total_pages:
            next_link = f"topics_{page_num + 1}.html"
            pagination += f'<a href="{next_link}">æ¬¡ã¸ Â»</a>'

        # Jinja2 context
        context = {
            "title": "ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§",
            "topics": page_items,
            "popular_topics": popular_topics[:10],
            "pagination": pagination,
            "sidebar_content": "",
        }
        render_template("topics.html", context, filename)

    print("âœ… ãƒˆãƒ”ãƒƒã‚¯ä¸€è¦§ãƒšãƒ¼ã‚¸ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")


def generate_dates_index(data):
    """Jinja2ã§ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã®æ—¥ä»˜ä¸€è¦§ã‚’ç”Ÿæˆ"""
    print("âœ… æ—¥ä»˜ä¸€è¦§ãƒšãƒ¼ã‚¸ç”Ÿæˆ")
    dates = sorted({page["date"] for page in data}, reverse=True)

    pages, total_pages = paginate_list(dates, items_per_page=20)

    for idx, page_items in enumerate(pages):
        page_num = idx + 1
        filename = (
            f"output/dates_{page_num}.html" if page_num > 1 else "output/dates.html"
        )

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ä½œæˆ
        pagination = ""
        if page_num > 1:
            prev_link = "dates.html" if page_num == 2 else f"dates_{page_num - 1}.html"
            pagination += f'<a href="{prev_link}">Â« å‰ã¸</a> '
        if page_num < total_pages:
            next_link = f"dates_{page_num + 1}.html"
            pagination += f'<a href="{next_link}">æ¬¡ã¸ Â»</a>'

        # Jinja2 context
        context = {
            "title": "æ—¥ä»˜ä¸€è¦§",
            "dates": page_items,
            "pagination": pagination,
            "sidebar_content": "",
        }
        render_template("dates.html", context, filename)

    print("âœ… æ—¥ä»˜ä¸€è¦§ãƒšãƒ¼ã‚¸ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")


def render_template(template_name, context, output_path):
    """Jinja2ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    template = env.get_template(template_name)
    output_from_parsed_template = template.render(context)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)  # å‡ºåŠ›å…ˆãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(output_from_parsed_template)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--use-cache", action="store_true", help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã™ã‚‹")
    args = parser.parse_args()

    data = fetch_notion_data(use_cache=args.use_cache)
    if data:
        print("âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†ï¼")
        generate_top_page(data)
        generate_topic_pages(data)
        generate_date_pages(data)
        generate_topics_index(data)
        generate_dates_index(data)
        generate_search_json.generate_search_data(data)
